{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Essentials: Data Cleaning\n",
    "    <Name>\n",
    "    <Class>\n",
    "    <Date>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "The g\\_t\\_results.csv file is a set of parent-reported scores on their child's Gifted and Talented tests. \n",
    "The two tests, OLSAT and NNAT, are used by NYC to determine if children are qualified for gifted programs.\n",
    "The OLSAT Verbal has 16 questions for Kindergardeners and 30 questions for first, second, and third graders.\n",
    "The NNAT has 48 questions. \n",
    "Using this dataset, answer the following questions.\n",
    "\n",
    "\n",
    "1) What column has the highest number of null values and what percent of its values are null? Print the answer as a tuple with (column name, percentage). Make sure the second value is a percent.\n",
    "\n",
    "2) List the columns that should be numeric that aren't. Print the answer as a tuple.\n",
    "\n",
    "3) How many third graders have scores outside the valid range for the OLSAT Verbal Score? Print the answer\n",
    "\n",
    "4) How many data values are missing (NaN)? Print the number.\n",
    "\n",
    "Each part is one point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: ('School Assigned', 0.24786324786324787)\n",
      "Question 2: ('OLSAT Verbal Score', 'OLSAT Verbal Percentile', 'NNAT Non Verbal Raw Score')\n",
      "Question 3: 1\n",
      "Question 4: 192\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"g_t_results.csv\")\n",
    "\n",
    "# Get the percentage of scores that aren't Nan\n",
    "col_sums = [(col, sum(df[col].value_counts())/len(df[col])) for col in df.columns]\n",
    "ans_1 = min(col_sums, key = lambda x: x[1])\n",
    "\n",
    "# Columns that should be numeric that aren't\n",
    "# print(df.dtypes)\n",
    "ans_2 = (\"OLSAT Verbal Score\", \"OLSAT Verbal Percentile\", \"NNAT Non Verbal Raw Score\")\n",
    "\n",
    "# How many third graders have scores outside valid range for OLSAT Verbal Score?\n",
    "third_graders = df[df['Entering Grade Level'] == '3']\n",
    "# print(third_graders['OLSAT Verbal Score'].value_counts().sort_index())\n",
    "ans_3 = 1\n",
    "\n",
    "# How many data values are missing?\n",
    "ans_4 = sum(df.isna().sum())\n",
    "\n",
    "for i, ans in enumerate([ans_1, ans_2, ans_3, ans_4]):\n",
    "    print(\"Question {}: {}\".format(i+1, ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "imdb.csv contains a small set of information about 99 movies. Clean the data set by doing the following in order: \n",
    "\n",
    "1) Remove duplicate rows by dropping the first **or** last. Print the shape of the dataframe after removing the rows.\n",
    "\n",
    "2) Drop all rows that contain missing data. Print the shape of the dataframe after removing the rows.\n",
    "\n",
    "3) Remove rows that have data outside valid data ranges and explain briefly how you determined your ranges for each column.\n",
    "\n",
    "4) Identify and drop columns with three or fewer different values. Print a tuple with the names of the columns dropped.\n",
    "\n",
    "5) Convert the titles to all lower case.\n",
    "\n",
    "Print the first five rows of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Before: (99, 13)\n",
      "1. Drop Duplicates: (91, 13)\n",
      "2. Drop Nan: (63, 13)\n",
      "3. Drop invalid data: (55, 13)\n",
      "4. Drop columns with <= 3 different values: ('color', 'language')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>director_name</th>\n",
       "      <th>duration</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>title_year</th>\n",
       "      <th>country</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>actors</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Martin Scorsese</td>\n",
       "      <td>240</td>\n",
       "      <td>116866727.0</td>\n",
       "      <td>Biography|Comedy|Crime|Drama</td>\n",
       "      <td>the wolf of wall street</td>\n",
       "      <td>2013</td>\n",
       "      <td>USA</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Leonardo DiCaprio,Matthew McConaughey,Jon Favreau</td>\n",
       "      <td>138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shane Black</td>\n",
       "      <td>195</td>\n",
       "      <td>408992272.0</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>iron man 3</td>\n",
       "      <td>2013</td>\n",
       "      <td>USA</td>\n",
       "      <td>200000000.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Robert Downey Jr.,Jon Favreau,Don Cheadle</td>\n",
       "      <td>95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>187</td>\n",
       "      <td>54116191.0</td>\n",
       "      <td>Crime|Drama|Mystery|Thriller|Western</td>\n",
       "      <td>the hateful eight</td>\n",
       "      <td>2015</td>\n",
       "      <td>USA</td>\n",
       "      <td>44000000.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Craig Stark,Jennifer Jason Leigh,Zoë Bell</td>\n",
       "      <td>114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>186</td>\n",
       "      <td>258355354.0</td>\n",
       "      <td>Adventure|Fantasy</td>\n",
       "      <td>the hobbit: the desolation of smaug</td>\n",
       "      <td>2013</td>\n",
       "      <td>USA</td>\n",
       "      <td>225000000.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Aidan Turner,Adam Brown,James Nesbitt</td>\n",
       "      <td>83000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Joss Whedon</td>\n",
       "      <td>173</td>\n",
       "      <td>623279547.0</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>the avengers</td>\n",
       "      <td>2012</td>\n",
       "      <td>USA</td>\n",
       "      <td>220000000.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Chris Hemsworth,Robert Downey Jr.,Scarlett Joh...</td>\n",
       "      <td>123000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       director_name  duration        gross  \\\n",
       "0    Martin Scorsese       240  116866727.0   \n",
       "1        Shane Black       195  408992272.0   \n",
       "2  Quentin Tarantino       187   54116191.0   \n",
       "4      Peter Jackson       186  258355354.0   \n",
       "9        Joss Whedon       173  623279547.0   \n",
       "\n",
       "                                 genres                          movie_title  \\\n",
       "0          Biography|Comedy|Crime|Drama              the wolf of wall street   \n",
       "1               Action|Adventure|Sci-Fi                           iron man 3   \n",
       "2  Crime|Drama|Mystery|Thriller|Western                    the hateful eight   \n",
       "4                     Adventure|Fantasy  the hobbit: the desolation of smaug   \n",
       "9               Action|Adventure|Sci-Fi                         the avengers   \n",
       "\n",
       "   title_year country       budget  imdb_score  \\\n",
       "0        2013     USA  100000000.0         8.2   \n",
       "1        2013     USA  200000000.0         7.2   \n",
       "2        2015     USA   44000000.0         7.9   \n",
       "4        2013     USA  225000000.0         7.9   \n",
       "9        2012     USA  220000000.0         8.1   \n",
       "\n",
       "                                              actors  movie_facebook_likes  \n",
       "0  Leonardo DiCaprio,Matthew McConaughey,Jon Favreau                138000  \n",
       "1          Robert Downey Jr.,Jon Favreau,Don Cheadle                 95000  \n",
       "2          Craig Stark,Jennifer Jason Leigh,Zoë Bell                114000  \n",
       "4              Aidan Turner,Adam Brown,James Nesbitt                 83000  \n",
       "9  Chris Hemsworth,Robert Downey Jr.,Scarlett Joh...                123000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"imdb.csv\")\n",
    "print(\"0. Before:\", df.shape)\n",
    "\n",
    "# Step 1: remove duplicate rows\n",
    "df = df.drop_duplicates([\"movie_title\"],keep=\"last\")\n",
    "print(\"1. Drop Duplicates:\", df.shape)\n",
    "\n",
    "# Step 2: remove missing data\n",
    "df = df.dropna()\n",
    "print(\"2. Drop Nan:\", df.shape)\n",
    "\n",
    "#Step 3: Remove data outside valid ranges\n",
    "# Numeric columns:\n",
    "# duration          30 - 300, a movie has to be at least a half hour\n",
    "#                             and under 5 hours long. \n",
    "# gross             1e3 - 1e9, movies make at least $1000 and less than $1 billion\n",
    "# title_year        1880 - 2030, Movies didn't exist before 1880's, \n",
    "#                                and none are planned for after 2030\n",
    "# budget            1e3 - 1e9, movies cost at least $1000 and less than $1 billion\n",
    "# imdb_score        0 - 10, that's the rating scale\n",
    "# movie_facebook_likes   0 - 7 trillion, at least 0 people liked it, less than 7 \n",
    "#                                        trillion people liked it\n",
    "df = df[df['duration'] > 30]\n",
    "df = df[df['duration'] < 300]\n",
    "df = df[df['gross'] > 1e3]\n",
    "df = df[df['gross'] < 1e9]\n",
    "df = df[df['title_year'] > 1880]\n",
    "df = df[df['title_year'] < 2030]\n",
    "df = df[df['budget'] > 1e3]\n",
    "df = df[df['budget'] < 1e9]\n",
    "df = df[df['imdb_score'] > 0]\n",
    "df = df[df['imdb_score'] < 10]\n",
    "df = df[df['movie_facebook_likes'] > 0]\n",
    "df = df[df['movie_facebook_likes'] < 7e12]\n",
    "print(\"3. Drop invalid data:\", df.shape)\n",
    "\n",
    "# Step 4: Drop columns with three or fewer different values. Print a tuple with the names of the columns dropped.\n",
    "#print(df.nunique())\n",
    "drop_cols = df.columns[df.nunique() <= 3]\n",
    "df = df.drop(drop_cols, axis=1)\n",
    "print(\"4. Drop columns with <= 3 different values:\", tuple(drop_cols))\n",
    "\n",
    "# Step 5. Convert the titles to all lower case \n",
    "df['movie_title'] = df['movie_title'].str.lower()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "basketball.csv contains data for all NBA players between 2001 and 2018.\n",
    "Each row represents a player's stats for a year.\n",
    "\n",
    "Create two new features:\n",
    "\n",
    "    career_length (int): number of years player has been playing (start at 0).\n",
    "    \n",
    "    target (str): The target team if the player is leaving. If the player is retiring, the target should be 'retires'.\n",
    "                  A player is retiring if their name doesn't exist the next year.\n",
    "                  (Set the players in 2019 to NaN).\n",
    "\n",
    "Remove all duplicate players in each year.\n",
    "Remove all rows except those where a player changes team, that is, target is not null nor 'retires'.\n",
    "\n",
    "Drop the player, year, and team_id columns.\n",
    "\n",
    "Return the first 10 lines of your dataframe and its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4866, 7)\n",
      "(1197, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>per</th>\n",
       "      <th>ws</th>\n",
       "      <th>bpm</th>\n",
       "      <th>career_length</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>33</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>14</td>\n",
       "      <td>WAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>2</td>\n",
       "      <td>WAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>28</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>8</td>\n",
       "      <td>MEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>32</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>11</td>\n",
       "      <td>SAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>27</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>LAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>26</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>DAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>27</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>7</td>\n",
       "      <td>CLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>29</td>\n",
       "      <td>22.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7</td>\n",
       "      <td>PHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>27</td>\n",
       "      <td>7.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>5</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>36</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>17</td>\n",
       "      <td>LAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age   per   ws  bpm  career_length target\n",
       "14   33  10.5  0.6 -1.1             14    WAS\n",
       "18   25   4.4  0.0 -6.6              2    WAS\n",
       "46   28   5.5 -0.3 -4.6              8    MEM\n",
       "49   32  10.8  0.1 -3.6             11    SAC\n",
       "62   27  11.0  2.4 -0.6              5    LAL\n",
       "64   26  15.6  0.6 -0.6              5    DAL\n",
       "66   27  12.4  0.5 -0.6              7    CLE\n",
       "70   29  22.3  1.3  6.9              7    PHI\n",
       "74   27   7.3 -0.1 -4.6              5    MIN\n",
       "84   36  11.5  0.2 -4.6             17    LAL"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('basketball.csv')\n",
    "print(df.shape)\n",
    "original_columns = df.columns\n",
    "grouped = df.groupby('player')\n",
    "df = df.set_index('player')\n",
    "\n",
    "# Calculate career length\n",
    "df['career_length'] = grouped['year'].max() - grouped['year'].min()\n",
    "df = df.reset_index()\n",
    "\n",
    "# Figure out target, retired, etc.\n",
    "df = df.sort_values(['player', 'year'])\n",
    "df['next_team'] = df.team_id.shift(-1)\n",
    "df['next_player'] = df.player.shift(-1)\n",
    "df['same_player'] = df['player'] == df['next_player']\n",
    "df['same_team'] = df['team_id'] == df['next_team']\n",
    "\n",
    "same_team_df = df[df['same_player'] == True].query('same_team == True')\n",
    "same_team_df['target'] = np.nan\n",
    "\n",
    "change_team_df = df[df['same_player'] == True].query('same_team == False')\n",
    "change_team_df['target'] = change_team_df['next_team']\n",
    "\n",
    "retired_df = df[df['same_player'] == False].query('year != 2019')\n",
    "retired_df['target'] = 'retired'\n",
    "\n",
    "current_df = df[df['year'] == 2019].query('same_player == False')\n",
    "current_df['target'] = np.nan\n",
    "\n",
    "new_df = pd.concat([same_team_df, change_team_df, current_df, retired_df])\n",
    "new_df = new_df.drop(['same_player', 'same_team', 'next_player', 'next_team'], axis=1)\n",
    "new_df = new_df.sort_values(['player', 'year'])\n",
    "\n",
    "# Remove all duplicate players in each year. \n",
    "# Remove all rows except those where a player changes team, that is, target is not null nor 'retires'.\n",
    "new_df = new_df.drop_duplicates(['player', 'year'], keep='first')\n",
    "new_df = new_df[new_df['target'] != np.nan]\n",
    "new_df = new_df.dropna()\n",
    "new_df = new_df[new_df.target != 'retired']\n",
    "\n",
    "# Drop the player, year, and team_id columns.\n",
    "new_df = new_df.drop(['player', 'year', 'team_id'], axis=1)\n",
    "new_df = new_df.sort_index()\n",
    "\n",
    "# Return the first 10 lines of your dataframe and its shape.\n",
    "print(new_df.shape)\n",
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "Load housing.csv into a dataframe with index=0. Descriptions of the features are in housing_data_description.txt.  \n",
    "The goal is to construct a regression model that predicts SalePrice using the other features of the dataset.  Do this as follows:\n",
    "\n",
    "\t1) Identify and handle the missing data.  Hint: Dropping every row with some missing data is not a good choice because it gives you an empty dataframe.  What can you do instead?\n",
    "    FIXME\n",
    "\t2) Identify the variable with nonnumeric values that are misencoded as numbers.  One-hot encode it. Hint: don't forget to remove one of the encoded columns to prevent collinearity with the constant column (which you will add later).\n",
    "    \n",
    "    3) Add a constant column to the dataframe.\n",
    "\n",
    "    4) Save a copy of the dataframe.\n",
    "\n",
    "\t5) Choose four categorical featrues that seem very important in predicting SalePrice. One-hot encode these features and remove all other categorical features.\n",
    "\t\t\n",
    "\t6) Run an OLS using all numerical data regression on your model.  \n",
    "\n",
    "\t\n",
    "Print the ten features that have the highest coef in your model and the summary. Don't print the OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          coef     std err      t  P>|t|       [0.025  \\\n",
      "Neighborhood_BrDale    13930.0    14600.00  0.956  0.339   -14700.000   \n",
      "Neighborhood_Veenker   14330.0    13000.00  1.105  0.269   -11100.000   \n",
      "MSZoning_RM            14890.0    11500.00  1.297  0.195    -7633.724   \n",
      "MSZoning_RL            17260.0    12300.00  1.402  0.161    -6880.701   \n",
      "MSZoning_RH            18470.0    14800.00  1.244  0.214   -10700.000   \n",
      "MSZoning_FV            21640.0    14700.00  1.469  0.142    -7255.289   \n",
      "Neighborhood_NoRidge   40290.0    10600.00  3.795  0.000    19500.000   \n",
      "Neighborhood_NridgHt   51490.0     9303.08  5.535  0.000    33200.000   \n",
      "Neighborhood_StoneBr   59060.0    10400.00  5.658  0.000    38600.000   \n",
      "constant              474900.0  1300000.00  0.365  0.715 -2070000.000   \n",
      "\n",
      "                         0.975]  \n",
      "Neighborhood_BrDale     42500.0  \n",
      "Neighborhood_Veenker    39800.0  \n",
      "MSZoning_RM             37400.0  \n",
      "MSZoning_RL             41400.0  \n",
      "MSZoning_RH             47600.0  \n",
      "MSZoning_FV             50500.0  \n",
      "Neighborhood_NoRidge    61100.0  \n",
      "Neighborhood_NridgHt    69700.0  \n",
      "Neighborhood_StoneBr    79500.0  \n",
      "constant              3020000.0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('housing.csv')\n",
    "\n",
    "# Clean up nans\n",
    "df['LotFrontage'] = df['LotFrontage'].fillna(0.0)\n",
    "df['MasVnrType'] = df['MasVnrType'].fillna('None')\n",
    "df['MasVnrArea'] = df['MasVnrArea'].fillna(0.0)\n",
    "df['Alley'] = df['Alley'].fillna('NA')\n",
    "df['BsmtQual'] = df['BsmtQual'].fillna('NA')\n",
    "df['BsmtCond'] = df['BsmtCond'].fillna('NA')\n",
    "df['BsmtExposure'] = df['BsmtExposure'].fillna('NA')\n",
    "df['BsmtFinType1'] = df['BsmtFinType1'].fillna('NA')\n",
    "df['BsmtFinType2'] = df['BsmtFinType2'].fillna('NA')\n",
    "df['FireplaceQu'] = df['FireplaceQu'].fillna('NA')\n",
    "df['GarageType'] = df['GarageType'].fillna('NA')\n",
    "df['GarageYrBlt'] = df['GarageYrBlt'].fillna('NA')\n",
    "df['GarageFinish'] = df['GarageFinish'].fillna('NA')\n",
    "df['GarageQual'] = df['GarageQual'].fillna('NA')\n",
    "df['GarageCond'] = df['GarageCond'].fillna('NA')\n",
    "df['PoolQC'] = df['PoolQC'].fillna('NA')\n",
    "df['Fence'] = df['Fence'].fillna('NA')\n",
    "df['MiscFeature'] = df['MiscFeature'].fillna('NA')\n",
    "# Drop Electrical Nan\n",
    "df = df[df['Electrical'].notna()]\n",
    "\n",
    "# 2) Identify the variable with nonnumeric values that are misencoded as numbers.\n",
    "#    One-hot encode it.\n",
    "# Is it MSSubClass?\n",
    "df = pd.get_dummies(df, columns=['MSSubClass'], drop_first=True)\n",
    "\n",
    "# 3) Add a constant column to the dataframe.\n",
    "df['constant'] = 1\n",
    "\n",
    "# 4) Save a copy of the dataframe.\n",
    "df_copy = df\n",
    "\n",
    "# 5) Choose four categorical featrues that seem very important in predicting SalePrice. \n",
    "#    One-hot encode these features and remove all other categorical features.\n",
    "# MSZoning, ExterCond, Neighborhood, BldgType\n",
    "df = pd.get_dummies(df, columns=['MSZoning', 'ExterCond', 'Neighborhood', 'BldgType'], \n",
    "                    drop_first=True)\n",
    "df = df._get_numeric_data()\n",
    "\n",
    "# 6) Run an OLS using all numerical data regression on your model.  \n",
    "results = sm.OLS(df['SalePrice'], df[df.columns[df.columns != 'SalePrice']]).fit()\n",
    "\n",
    "results_summary =  results.summary()\n",
    "results_as_html = results_summary.tables[1].as_html()\n",
    "df_res = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "df_res = df_res.sort_values('coef')\n",
    "print(df_res.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "Using the copy of the dataframe you created in Problem 4, one-hot encode all the categorical variables.\n",
    "Print the shape of the dataframe and run OLS.\n",
    "\n",
    "Print the ten features that have the highest coef in your model and the summary.\n",
    "Write a couple of sentences discussing which model is better and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1459, 371)\n",
      "                      coef  std err       t  P>|t|    [0.025    0.975]\n",
      "GarageCond_TA     132400.0  36000.0   3.676  0.000   61700.0  203000.0\n",
      "GarageCond_Gd     133000.0  37900.0   3.507  0.000   58600.0  207000.0\n",
      "GarageCond_Po     137400.0  40800.0   3.364  0.001   57300.0  217000.0\n",
      "RoofMatl_Roll     605800.0  60500.0  10.006  0.000  487000.0  725000.0\n",
      "RoofMatl_Tar&Grv  618800.0  58100.0  10.644  0.000  505000.0  733000.0\n",
      "RoofMatl_WdShake  624400.0  56900.0  10.973  0.000  513000.0  736000.0\n",
      "RoofMatl_CompShg  624700.0  54300.0  11.496  0.000  518000.0  731000.0\n",
      "RoofMatl_Metal    682600.0  64300.0  10.616  0.000  556000.0  809000.0\n",
      "RoofMatl_WdShngl  683800.0  55400.0  12.350  0.000  575000.0  792000.0\n",
      "RoofMatl_Membran  703200.0  64700.0  10.867  0.000  576000.0  830000.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df_copy, drop_first=True)\n",
    "print(\"Shape:\", df.shape)\n",
    "results = sm.OLS(df['SalePrice'], df[df.columns[df.columns != 'SalePrice']]).fit()\n",
    "\n",
    "results_summary =  results.summary()\n",
    "results_as_html = results_summary.tables[1].as_html()\n",
    "df_res = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "df_res = df_res.sort_values('coef')\n",
    "print(df_res.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that the previous model is better with less features... This model seems to put a huge amount of emphasis on Garages and Roof materials, which are indicative of other features, such as what neighborhood it's in, etc. A huge house with lots of rooms is more likely to have a fancier roof/garage, so by just adding in those certain things"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
